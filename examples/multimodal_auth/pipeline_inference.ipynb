{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woleek/SynthWeave/.venv/lib/python3.12/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.3'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from unimodal import AdaFace, ReDimNet\n",
    "from pipe import MultiModalAuthPipeline, ImagePreprocessor, AudioPreprocessor\n",
    "from synthweave.utils.datasets import get_datamodule\n",
    "from synthweave.utils.fusion import get_fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_proc = ImagePreprocessor(window_len=4, step=2)\n",
    "aud_proc = AudioPreprocessor(window_len=4, step=2)\n",
    "\n",
    "ds_kwargs = {\n",
    "    'video_processor': vid_proc, 'audio_processor': aud_proc, 'mode': 'minimal'\n",
    "}\n",
    "\n",
    "dm = get_datamodule(\"DeepSpeak_v1\", batch_size=1, dataset_kwargs=ds_kwargs, \n",
    "                    sample_mode='single', # single, sequence\n",
    "                    clip_mode='id', # 'id', 'idx'\n",
    "                    clip_to=1, # 'min', int\n",
    "                    clip_selector='first', # 'first', 'random'\n",
    ")\n",
    "\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE EXTRACTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/woleek/.cache/torch/hub/IDRnD_ReDimNet_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/woleek/.cache/torch/hub/IDRnD_ReDimNet_master\n",
      "load_res : <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "aud_model = ReDimNet(\n",
    "    freeze=True\n",
    ")\n",
    "\n",
    "img_model = AdaFace(\n",
    "    path='../../../models',\n",
    "    freeze=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] This fusion expects embeddings of shape (batch_size, embed_dim).\n"
     ]
    }
   ],
   "source": [
    "FUSION = \"CFF\"\n",
    "EMB_DIM = 256\n",
    "\n",
    "fusion = get_fusion(\n",
    "    fusion_name=FUSION,\n",
    "    output_dim=EMB_DIM,\n",
    "    modality_keys=[\"video\", \"audio\"],\n",
    "    out_proj_dim=256,\n",
    "    \n",
    "    # num_att_heads=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = MultiModalAuthPipeline(\n",
    "    models={\n",
    "        'audio': aud_model,\n",
    "        'video': img_model\n",
    "    },\n",
    "    fusion=fusion,\n",
    "    detection_head=torch.nn.Sequential(torch.nn.Linear(EMB_DIM, 1), torch.nn.Sigmoid()),\n",
    "    freeze_backbone=True,\n",
    ")\n",
    "\n",
    "pipe.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 112, 112]) torch.Size([1, 1, 64000])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sample = next(iter(train_loader))\n",
    "\n",
    "print(sample['video'].shape, sample['audio'].shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = pipe(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256]), torch.Size([1, 512]), torch.Size([1, 192]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['embedding'].shape, out['video'].shape, out['audio'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fake'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'fake' if out['logits'].item() > 0.5 else 'real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['video_ref'] = torch.rand_like(out['video'])\n",
    "out['audio_ref'] = torch.rand_like(out['audio'])\n",
    "\n",
    "# out['video_ref'] = out['video'].clone()\n",
    "# out['audio_ref'] = out['audio'].clone()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sim = pipe.verify(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.457475662231445, 1.972063422203064)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim['video'][0].item(), sim['audio'][0].item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
